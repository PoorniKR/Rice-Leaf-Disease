{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1742536776142,"user":{"displayName":"Poornima","userId":"15321569832946116621"},"user_tz":-330},"id":"bpglkKI59M2x","outputId":"77a8dd05-86e0-473c-ba43-f8887a3da5b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Class: brown_spot, Number of Images: 1480\n","Class: narrow_brown_spot, Number of Images: 1416\n","Class: tungro, Number of Images: 1740\n","Class: rice_hispa, Number of Images: 1461\n","Class: bacterial_leaf_blight, Number of Images: 1386\n","Class: healthy, Number of Images: 1491\n","Class: leaf_scald, Number of Images: 1670\n","Class: neck_blast, Number of Images: 1000\n","Class: sheath_blight, Number of Images: 1578\n","Class: leaf_blast, Number of Images: 1801\n"]}],"source":["import os\n","\n","dataset_path = '/home/aubct/Documents/RiceLeafDataset'\n","for class_name in os.listdir(dataset_path):\n","    class_path = os.path.join(dataset_path, class_name)\n","    print(f\"Class: {class_name}, Number of Images: {len(os.listdir(class_path))}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q1AZ96JhD1eM"},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","def load_and_preprocess_images(dataset_path, size=(299, 299)):\n","    images = []\n","    labels = []\n","\n","    for class_name in os.listdir(dataset_path):\n","        class_path = os.path.join(dataset_path, class_name)\n","        for filename in os.listdir(class_path):\n","            img_path = os.path.join(class_path, filename)\n","            img = cv2.imread(img_path)\n","            img_resized = cv2.resize(img, size)\n","            img_denoised = cv2.bilateralFilter(img_resized, d=11, sigmaColor=75, sigmaSpace=60)\n","            img_gray = cv2.cvtColor(img_denoised, cv2.COLOR_BGR2GRAY)\n","\n","            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","            img_clahe = clahe.apply(img_gray)\n","\n","            edges = cv2.Canny(img_clahe, 100, 200)\n","\n","            img_combined = cv2.addWeighted(img_clahe, 0.7, edges, 0.3, 0)\n","\n","            images.append(img_combined)\n","            labels.append(class_name)\n","\n","    return np.array(images), np.array(labels)\n","\n","X, y = load_and_preprocess_images(dataset_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":910,"status":"ok","timestamp":1742114140716,"user":{"displayName":"Poornima","userId":"15321569832946116621"},"user_tz":-330},"id":"5Ou7EePHLIxG","outputId":"9a091424-745c-47c1-8411-23622f4047c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thresholded Images shape: (15023, 299, 299)\n"]}],"source":["def apply_adaptive_thresholding(images):\n","    segmented_images = []\n","\n","    for img in images:\n","        adaptive_thresh = cv2.adaptiveThreshold(\n","            img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n","            cv2.THRESH_BINARY_INV, 11, 2\n","        )\n","        segmented_images.append(adaptive_thresh)\n","\n","    return np.array(segmented_images)\n","\n","X_thresholded = apply_adaptive_thresholding(X)\n","\n","print(f\"Thresholded Images shape: {X_thresholded.shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPpWslBfrGjQ","outputId":"7ee41aac-09c6-4339-f5fa-1b1a1ed0a0c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thresholded images saved successfully!\n"]}],"source":["import h5py\n","import numpy as np\n","\n","with h5py.File(\"thresholded_images.h5\", \"w\") as hf:\n","    hf.create_dataset(\"X_thresholded\", data=X_thresholded)\n","\n","print(\"Thresholded images saved successfully!\")\n","\n","with h5py.File(\"preprocessed_data.h5\", \"w\") as hf:\n","    hf.create_dataset(\"X\", data=X)\n","    hf.create_dataset(\"y\", data=y.astype(\"S\"))\n","\n","print(\"Preprocessed images and labels saved successfully!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"niImGb0DrGjR","outputId":"2573c067-2a50-4ec3-ea18-08464368aa0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded Images shape: (15023, 299, 299)\n"]}],"source":["import h5py\n","import numpy as np\n","\n","with h5py.File(\"thresholded_images.h5\", \"r\") as hf:\n","    X_thresholded = np.array(hf[\"X_thresholded\"])\n","\n","print(f\"Loaded Images shape: {X_thresholded.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5K650x7RrGjR","outputId":"fbd264ab-244e-4e49-94b9-ecc6848ad79a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Preprocessed images and labels saved successfully!\n"]}],"source":["import h5py\n","\n","with h5py.File(\"preprocessed_data.h5\", \"w\") as hf:\n","    hf.create_dataset(\"X\", data=X)\n","    hf.create_dataset(\"y\", data=y.astype(\"S\"))\n","\n","print(\"Preprocessed images and labels saved successfully!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZk69PAErGjR","outputId":"0312dafb-3495-49ba-8a8d-d973683ba414"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded Images shape: (15023, 299, 299)\n","Loaded Labels shape: (15023,)\n"]}],"source":["import h5py\n","import numpy as np\n","\n","with h5py.File(\"preprocessed_data.h5\", \"r\") as hf:\n","    X_loaded = np.array(hf[\"X\"])\n","    y_loaded = np.array(hf[\"y\"]).astype(str)\n","\n","print(f\"Loaded Images shape: {X_loaded.shape}\")\n","print(f\"Loaded Labels shape: {y_loaded.shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2363,"status":"ok","timestamp":1742114161353,"user":{"displayName":"Poornima","userId":"15321569832946116621"},"user_tz":-330},"id":"CaVwi80_F_6D","outputId":"f7cda387-5056-4fa9-d619-056495b56699"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1 1 1 ... 3 3 3]\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y_loaded)\n","print(y_encoded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6hzTBVxarGjS","outputId":"24a5a133-f23c-40a2-a356-0f677328d408"},"outputs":[{"data":{"text/plain":["['label_encoder.pkl']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import joblib\n","joblib.dump(label_encoder, \"label_encoder.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":394,"status":"ok","timestamp":1742114171036,"user":{"displayName":"Poornima","userId":"15321569832946116621"},"user_tz":-330},"id":"qiT5LkyhVIf_","outputId":"a391fdcc-e9f6-4a63-e15f-98114f566bba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training set: 12018 images\n","Validation set: 1502 images\n","Test set: 1503 images\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_temp, y_train, y_temp = train_test_split(X_loaded, y_encoded, test_size=0.2, random_state=42)\n","\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","print(f\"Training set: {len(X_train)} images\")\n","print(f\"Validation set: {len(X_val)} images\")\n","print(f\"Test set: {len(X_test)} images\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aC4GlSCkrGjT"},"outputs":[],"source":["X_train_rgb = np.stack([X_train] * 3, axis=-1)\n","X_val_rgb = np.stack([X_val] * 3, axis=-1)\n","X_test_rgb = np.stack([X_test] * 3, axis=-1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPv4TeTZrGjT","outputId":"3a05388c-393c-45ea-8b74-268ba70b312b"},"outputs":[{"name":"stdout","output_type":"stream","text":["float32 float32 float32\n"]}],"source":["import numpy as np\n","\n","def batch_normalize(X, batch_size=1000):\n","    X = X.astype(np.float32)\n","    for i in range(0, len(X), batch_size):\n","        X[i:i+batch_size] /= 255.0\n","    return X\n","\n","X_train_rgb = batch_normalize(X_train_rgb)\n","X_val_rgb = batch_normalize(X_val_rgb)\n","X_test_rgb = batch_normalize(X_test_rgb)\n","\n","print(X_train_rgb.dtype, X_val_rgb.dtype, X_test_rgb.dtype)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DTfv5JXorGjT","outputId":"87f446be-93c0-4060-92af-5dd71716954a"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0 1.0\n"]}],"source":["print(np.min(X_train_rgb), np.max(X_train_rgb))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Io4HWMSPrGjT","outputId":"c1a5b592-6e82-4e30-f204-e89fc5a14973"},"outputs":[{"name":"stdout","output_type":"stream","text":["(12018, 299, 299, 3)\n","(1502, 299, 299, 3)\n","(1503, 299, 299, 3)\n"]}],"source":["print(X_train_rgb.shape)\n","print(X_val_rgb.shape)\n","print(X_test_rgb.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4OWeJ22JrGjT","outputId":"7527ec05-1b79-4b36-f79f-754bc4537668"},"outputs":[{"name":"stdout","output_type":"stream","text":["Labels saved successfully.\n"]}],"source":["with h5py.File('labels.h5', 'w') as f:\n","    f.create_dataset('y_encoded', data=y_encoded)\n","    f.create_dataset('classes', data=np.array(label_encoder.classes_, dtype='S'))\n","    f.create_dataset(\"y_train\", data=y_train)\n","    f.create_dataset(\"y_val\", data=y_val)\n","    f.create_dataset(\"y_test\", data=y_test)\n","\n","print(\"Labels saved successfully.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ipoGT5D6rGjT","outputId":"be994084-0748-47eb-d689-df7b4ef62291"},"outputs":[{"name":"stdout","output_type":"stream","text":["Datasets saved successfully!\n"]}],"source":["import h5py\n","\n","with h5py.File(\"rgb_datasets.h5\", \"w\") as hf:\n","    hf.create_dataset(\"X_train_rgb\", data=X_train_rgb)\n","    hf.create_dataset(\"X_val_rgb\", data=X_val_rgb)\n","    hf.create_dataset(\"X_test_rgb\", data=X_test_rgb)\n","\n","print(\"Datasets saved successfully!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sanu6spqrGjT","outputId":"d82469c0-cb70-43a4-eb8a-3ecd659678e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Set Shape: (12018, 299, 299, 3)\n","Validation Set Shape: (1502, 299, 299, 3)\n","Test Set Shape: (1503, 299, 299, 3)\n"]}],"source":["import h5py\n","import numpy as np\n","\n","with h5py.File(\"rgb_datasets.h5\", \"r\") as hf:\n","    X_train_rgb = np.array(hf[\"X_train_rgb\"])\n","    X_val_rgb = np.array(hf[\"X_val_rgb\"])\n","    X_test_rgb = np.array(hf[\"X_test_rgb\"])\n","\n","print(f\"Train Set Shape: {X_train_rgb.shape}\")\n","print(f\"Validation Set Shape: {X_val_rgb.shape}\")\n","print(f\"Test Set Shape: {X_test_rgb.shape}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}